{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Algorítmico con GRU y Backtrader\n",
    "\n",
    "Este notebook sigue el tutorial `gru_tutorial.md`. Aquí implementaremos el flujo de trabajo completo: desde la preparación de los datos y el entrenamiento del modelo GRU hasta la creación y ejecución de una estrategia de trading en `backtrader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y Preparar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el conjunto de datos de precios de acciones\n",
    "df = pd.read_csv('../yahoo/AAPL.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Seleccionar la columna 'close' para el análisis\n",
    "data = df[['close']]\n",
    "\n",
    "# Escalar los datos al rango [0, 1] para un mejor rendimiento del modelo\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Función para crear secuencias de datos para el modelo GRU\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definir la longitud de la secuencia para el modelo\n",
    "SEQ_LENGTH = 60\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Imprimir las formas de los conjuntos de datos para verificar\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construir y Entrenar el Modelo GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el modelo GRU usando Keras Sequential API\n",
    "model = Sequential([\n",
    "    # Primera capa GRU con 50 unidades, retorna secuencias para la siguiente capa\n",
    "    GRU(50, return_sequences=True, input_shape=(SEQ_LENGTH, 1)),\n",
    "    # Capa de Dropout para regularización y prevenir sobreajuste\n",
    "    Dropout(0.2),\n",
    "    # Segunda capa GRU con 50 unidades\n",
    "    GRU(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    # Capa densa con 25 neuronas\n",
    "    Dense(25),\n",
    "    # Capa de salida con una neurona para predecir el precio\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo con el optimizador 'adam' y la pérdida de error cuadrático medio\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Mostrar un resumen de la arquitectura del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento y validarlo con los datos de prueba\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Guardar el Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado en un archivo HDF5 para su uso posterior\n",
    "model.save('gru_model.h5')\n",
    "print('Modelo guardado como gru_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "# Invertir la escala de las predicciones para obtener los precios reales\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "# Invertir la escala de los datos de prueba para comparación\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Graficar los precios reales vs. los precios predichos\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(data.index[train_size + SEQ_LENGTH:], y_test_inv, color='blue', label='Precio Real')\n",
    "plt.plot(data.index[train_size + SEQ_LENGTH:], predictions, color='red', label='Precio Predicho')\n",
    "plt.title('Predicción de Precios de AAPL')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Precio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Crear la Estrategia en `backtrader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias para backtesting\n",
    "import backtrader as bt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Definir la estrategia de trading basada en el modelo GRU\n",
    "class GRUStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        # Cargar el modelo GRU pre-entrenado\n",
    "        self.model = load_model('gru_model.h5')\n",
    "        # Mantener el escalador para transformar los datos\n",
    "        self.scaler = scaler\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "        self.data_close = self.datas[0].close\n",
    "\n",
    "    def next(self):\n",
    "        # Asegurarse de que hay suficientes datos para crear una secuencia\n",
    "        if len(self.data_close) > self.seq_length:\n",
    "            # Preparar los datos más recientes para la predicción\n",
    "            last_data = np.array(self.data_close.get(size=self.seq_length))\n",
    "            last_data_scaled = self.scaler.transform(last_data.reshape(-1, 1))\n",
    "            X_pred = np.array([last_data_scaled])\n",
    "            \n",
    "            # Predecir el precio del siguiente día\n",
    "            prediction_scaled = self.model.predict(X_pred)\n",
    "            prediction = self.scaler.inverse_transform(prediction_scaled)[0][0]\n",
    "            \n",
    "            # Lógica de trading simple: comprar si la predicción es mayor que el precio actual, vender si es menor\n",
    "            if prediction > self.data_close[0]:\n",
    "                if not self.position: # Si no hay una posición abierta\n",
    "                    self.buy() # Comprar\n",
    "            elif prediction < self.data_close[0]:\n",
    "                if self.position: # Si hay una posición abierta\n",
    "                    self.sell() # Vender\n",
    "\n",
    "# Instanciar el motor de backtesting de backtrader\n",
    "cerebro = bt.Cerebro()\n",
    "\n",
    "# Añadir el feed de datos al motor\n",
    "data_feed = bt.feeds.PandasData(dataname=df)\n",
    "cerebro.adddata(data_feed)\n",
    "\n",
    "# Añadir la estrategia de trading al motor\n",
    "cerebro.addstrategy(GRUStrategy)\n",
    "\n",
    "# Configurar el capital inicial y la comisión por operación\n",
    "cerebro.broker.setcash(100000.0)\n",
    "cerebro.broker.setcommission(commission=0.001)\n",
    "\n",
    "# Imprimir el capital inicial y ejecutar el backtest\n",
    "print(f'Capital Inicial: {cerebro.broker.getvalue()}')\n",
    "cerebro.run()\n",
    "# Imprimir el capital final después del backtesting\n",
    "print(f'Capital Final: {cerebro.broker.getvalue()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}