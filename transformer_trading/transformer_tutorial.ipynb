{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Algorítmico con Transformers y Backtrader\n",
    "\n",
    "Este notebook sigue el tutorial `transformer_tutorial.md`. Aquí implementaremos el flujo de trabajo completo: desde la preparación de los datos y el entrenamiento del modelo Transformer hasta la creación y ejecución de una estrategia de trading en `backtrader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y Preparar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg') # Usar el backend no interactivo para evitar problemas en entornos sin GUI\n",
    "import pandas as pd # Librería para manipulación de datos\n",
    "import pandas_ta as ta # Extensión de pandas para análisis técnico\n",
    "import numpy as np # Librería para operaciones numéricas\n",
    "from sklearn.preprocessing import MinMaxScaler # Para escalar los datos\n",
    "import tensorflow as tf # Framework de Deep Learning\n",
    "from tensorflow.keras.models import Model, load_model # Para construir y cargar modelos\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D # Capas para el modelo Transformer\n",
    "import matplotlib.pyplot as plt # Para visualización de datos\n",
    "import backtrader as bt # Framework para backtesting de estrategias de trading\n",
    "\n",
    "# Cargar los datos históricos desde un archivo CSV\n",
    "# 'index_col' y 'parse_dates' ayudan a tratar la columna de fecha como un índice de tipo datetime\n",
    "df = pd.read_csv('../yahoo/AAPL.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Añadir indicadores técnicos al DataFrame usando pandas_ta\n",
    "df.ta.rsi(length=14, append=True) # Índice de Fuerza Relativa\n",
    "df.ta.macd(fast=12, slow=26, signal=9, append=True) # Media Móvil de Convergencia/Divergencia\n",
    "df.ta.bbands(length=20, append=True) # Bandas de Bollinger\n",
    "df.ta.atr(length=14, append=True) # Rango Verdadero Promedio\n",
    "df.ta.stoch(length=14, append=True) # Oscilador Estocástico\n",
    "\n",
    "# Eliminar filas con valores NaN que se generan al calcular los indicadores\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Definir la lista de características (features) que se usarán para entrenar el modelo\n",
    "features = [\n",
    "    'close', # Precio de cierre\n",
    "    'RSI_14', # RSI\n",
    "    'MACD_12_26_9', # MACD\n",
    "    'BBL_20_2.0', # Banda de Bollinger inferior\n",
    "    'BBM_20_2.0', # Banda de Bollinger media\n",
    "    'BBU_20_2.0', # Banda de Bollinger superior\n",
    "    'ATRr_14', # ATR\n",
    "    'STOCHk_14_3_3', # Estocástico %K\n",
    "    'STOCHd_14_3_3'  # Estocástico %D\n",
    "]\n",
    "\n",
    "# Corrección de nombres de columnas de bbands, ya que pandas_ta puede generar nombres ligeramente diferentes\n",
    "for col in df.columns:\n",
    "    if 'BBL_20_2.0' in col:\n",
    "        features[3] = col\n",
    "    if 'BBM_20_2.0' in col:\n",
    "        features[4] = col\n",
    "    if 'BBU_20_2.0' in col:\n",
    "        features[5] = col\n",
    "\n",
    "# Crear un DataFrame 'data' solo con las características seleccionadas\n",
    "data = df[features]\n",
    "n_features = len(features) # Número total de características\n",
    "\n",
    "# Inicializar el escalador para normalizar todas las características a un rango entre 0 y 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data) # Ajustar y transformar los datos\n",
    "\n",
    "# Inicializar un segundo escalador solo para el precio de cierre ('close')\n",
    "# Esto facilitará la inversión de la escala de las predicciones del modelo\n",
    "scaler_pred = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_pred.fit_transform(data[['close']])\n",
    "\n",
    "# Función para crear secuencias de datos para el modelo de series temporales\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], [] # Listas para las secuencias de entrada (X) y las etiquetas de salida (y)\n",
    "    # Itera sobre los datos para crear las secuencias\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # La secuencia de entrada (X) contiene 'seq_length' pasos de tiempo con todas las características\n",
    "        X.append(data[i:i + seq_length])\n",
    "        # La etiqueta (y) es el precio de cierre ('close', feature en la posición 0) del siguiente paso de tiempo\n",
    "        y.append(data[i + seq_length, 0])\n",
    "    return np.array(X), np.array(y) # Devuelve las listas como arrays de NumPy\n",
    "\n",
    "# Definir la longitud de la secuencia (cuántos pasos de tiempo mirar hacia atrás)\n",
    "SEQ_LENGTH = 60\n",
    "# Crear las secuencias de entrenamiento a partir de los datos escalados\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construir y Entrenar el Modelo Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = Dense(dim, activation=\"relu\")(x)\n",
    "        x = Dropout(mlp_dropout)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = build_transformer_model(\n",
    "    (SEQ_LENGTH, n_features),\n",
    "    head_size=128,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[64],\n",
    "    dropout=0.1,\n",
    "    mlp_dropout=0.1\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Guardar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('transformer_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = scaler_pred.inverse_transform(predictions)\n",
    "y_test_inv = scaler_pred.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plot_index = data.index[train_size + SEQ_LENGTH:]\n",
    "plt.plot(plot_index, y_test_inv, color='blue', label='Precio Real')\n",
    "plt.plot(plot_index, predictions, color='red', label='Precio Predicho')\n",
    "plt.title('Predicción de Precios con Transformer')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Precio')\n",
    "plt.legend()\n",
    "plt.savefig('prediction_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estrategia en backtrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        self.model = load_model('transformer_model.keras')\n",
    "        self.scaler = scaler\n",
    "        self.scaler_pred = scaler_pred\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "\n",
    "        self.data_close = self.datas[0].close\n",
    "        self.rsi = bt.indicators.RSI(self.datas[0], period=14)\n",
    "        self.macd = bt.indicators.MACD(self.datas[0], period_me1=12, period_me2=26, period_signal=9)\n",
    "        self.bbands = bt.indicators.BollingerBands(self.datas[0], period=20)\n",
    "        self.atr = bt.indicators.AverageTrueRange(self.datas[0], period=14)\n",
    "        self.stoch = bt.indicators.Stochastic(self.datas[0], period=14)\n",
    "\n",
    "    def next(self):\n",
    "        if len(self) < self.seq_length + 26:\n",
    "            return\n",
    "\n",
    "        close_vals = self.data_close.get(size=self.seq_length)\n",
    "        rsi_vals = self.rsi.get(size=self.seq_length)\n",
    "        macd_vals = self.macd.macd.get(size=self.seq_length)\n",
    "        bbl_vals = self.bbands.lines.bot.get(size=self.seq_length)\n",
    "        bbm_vals = self.bbands.lines.mid.get(size=self.seq_length)\n",
    "        bbu_vals = self.bbands.lines.top.get(size=self.seq_length)\n",
    "        atr_vals = self.atr.get(size=self.seq_length)\n",
    "        stochk_vals = self.stoch.lines.percK.get(size=self.seq_length)\n",
    "        stochd_vals = self.stoch.lines.percD.get(size=self.seq_length)\n",
    "\n",
    "        input_array = np.array([\n",
    "            close_vals, rsi_vals, macd_vals, \n",
    "            bbl_vals, bbm_vals, bbu_vals, \n",
    "            atr_vals, \n",
    "            stochk_vals, stochd_vals\n",
    "        ]).T\n",
    "\n",
    "        scaled_input = self.scaler.transform(input_array)\n",
    "        X_pred = np.array([scaled_input])\n",
    "\n",
    "        prediction_scaled = self.model.predict(X_pred)\n",
    "        prediction = self.scaler_pred.inverse_transform(prediction_scaled)[0][0]\n",
    "\n",
    "        if prediction > self.data_close[0]:\n",
    "            if not self.position:\n",
    "                self.buy()\n",
    "        elif prediction < self.data_close[0]:\n",
    "            if self.position:\n",
    "                self.sell()\n",
    "\n",
    "cerebro = bt.Cerebro()\n",
    "data_feed = bt.feeds.PandasData(dataname=df)\n",
    "cerebro.adddata(data_feed)\n",
    "cerebro.addstrategy(TransformerStrategy)\n",
    "cerebro.broker.setcash(100000.0)\n",
    "cerebro.broker.setcommission(commission=0.001)\n",
    "\n",
    "print(f'Capital Inicial: {cerebro.broker.getvalue()}')\n",
    "cerebro.run()\n",
    "print(f'Capital Final: {cerebro.broker.getvalue()}')\n",
    "\n",
    "# Solución para evitar que el gráfico intente mostrarse en un entorno no interactivo\n",
    "_original_show = plt.show\n",
    "plt.show = lambda: None\n",
    "\n",
    "fig = cerebro.plot(style='candlestick')[0][0]\n",
    "fig.savefig('backtest_plot.png')\n",
    "\n",
    "# Restaurar la función original\n",
    "plt.show = _original_show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
