{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Algorítmico con Transformers y Backtrader\n",
    "\n",
    "Este notebook sigue el tutorial `transformer_tutorial.md`. Aquí implementaremos el flujo de trabajo completo: desde la preparación de los datos y el entrenamiento del modelo Transformer hasta la creación y ejecución de una estrategia de trading en `backtrader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y Preparar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg') # Configura Matplotlib para no usar una GUI interactiva. Esencial para scripts.\n",
    "import pandas as pd # Importa pandas para la manipulación de datos, una herramienta clave en data science.\n",
    "import pandas_ta as ta # Extiende pandas con funciones de análisis técnico.\n",
    "import numpy as np # Importa numpy para operaciones numéricas eficientes.\n",
    "from sklearn.preprocessing import MinMaxScaler # Para normalizar los datos, un paso crucial en el preprocesamiento.\n",
    "import tensorflow as tf # El framework de deep learning que usaremos para construir el Transformer.\n",
    "from tensorflow.keras.models import Model, load_model # Funciones para definir y cargar modelos de Keras.\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D # Capas para el modelo.\n",
    "import matplotlib.pyplot as plt # Para la visualización de datos y resultados.\n",
    "import backtrader as bt # El framework de backtesting para probar nuestra estrategia de trading.\n",
    "\n",
    "# Carga de datos desde un CSV. `index_col` y `parse_dates` son para manejar correctamente las fechas.\n",
    "df = pd.read_csv('../yahoo/AAPL.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Cálculo de indicadores técnicos. `append=True` los añade como nuevas columnas al DataFrame.\n",
    "df.ta.rsi(length=14, append=True) # Relative Strength Index (RSI)\n",
    "df.ta.macd(fast=12, slow=26, signal=9, append=True) # Moving Average Convergence Divergence (MACD)\n",
    "df.ta.bbands(length=20, append=True) # Bollinger Bands\n",
    "df.ta.atr(length=14, append=True) # Average True Range (ATR)\n",
    "df.ta.stoch(length=14, append=True) # Stochastic Oscillator\n",
    "\n",
    "# Eliminamos las filas con valores NaN, que aparecen por el cálculo de los indicadores con ventanas de tiempo.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Definimos las características (features) que alimentarán nuestro modelo.\n",
    "features = [\n",
    "    'close', 'RSI_14', 'MACD_12_26_9', 'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', \n",
    "    'ATRr_14', 'STOCHk_14_3_3', 'STOCHd_14_3_3'\n",
    "]\n",
    "\n",
    "# pandas_ta a veces crea nombres de columna ligeramente diferentes. Este bucle los corrige.\n",
    "for col in df.columns:\n",
    "    if 'BBL_20_2.0' in col: features[3] = col\n",
    "    if 'BBM_20_2.0' in col: features[4] = col\n",
    "    if 'BBU_20_2.0' in col: features[5] = col\n",
    "\n",
    "# Creamos un nuevo DataFrame `data` solo con las features que nos interesan.\n",
    "data = df[features]\n",
    "n_features = len(features) # Guardamos el número de características.\n",
    "\n",
    "# Normalizamos los datos para que estén en un rango de 0 a 1. Esto mejora el rendimiento del modelo.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Creamos un segundo scaler solo para el precio de cierre. Lo usaremos para des-normalizar las predicciones.\n",
    "scaler_pred = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_pred.fit_transform(data[['close']])\n",
    "\n",
    "# Función para crear secuencias de datos. Los modelos de series temporales necesitan datos en este formato.\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length]) # `X` es una secuencia de `seq_length` pasos.\n",
    "        y.append(data[i + seq_length, 0]) # `y` es el precio de cierre del siguiente paso.\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definimos la longitud de la secuencia. Usaremos 60 días de datos para predecir el siguiente.\n",
    "SEQ_LENGTH = 60\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "# Dividimos los datos en un conjunto de entrenamiento (80%) y uno de prueba (20%).\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construir y Entrenar el Modelo Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque codificador del Transformer. Contiene atención multi-cabeza y una red feed-forward.\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalización y Atención Multi-cabeza\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs # Conexión residual\n",
    "\n",
    "    # Red Feed-Forward\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res # Segunda conexión residual\n",
    "\n",
    "# Función para construir el modelo Transformer completo.\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    # Apilamos varios bloques de codificador.\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    # Pooling para reducir la dimensionalidad y una red MLP para la salida final.\n",
    "    x = GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = Dense(dim, activation=\"relu\")(x)\n",
    "        x = Dropout(mlp_dropout)(x)\n",
    "    outputs = Dense(1)(x) # La salida es un único valor: el precio predicho.\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Construimos el modelo con los hiperparámetros definidos.\n",
    "model = build_transformer_model(\n",
    "    (SEQ_LENGTH, n_features), head_size=128, num_heads=4, ff_dim=4,\n",
    "    num_transformer_blocks=4, mlp_units=[64], dropout=0.1, mlp_dropout=0.1\n",
    ")\n",
    "\n",
    "# Compilamos el modelo. Usamos Adam como optimizador y el error cuadrático medio como función de pérdida.\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary() # Mostramos un resumen de la arquitectura del modelo.\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento.\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Guardar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo entrenado para poder usarlo más tarde sin necesidad de re-entrenar.\n",
    "model.save('transformer_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos predicciones sobre el conjunto de prueba.\n",
    "predictions = model.predict(X_test)\n",
    "# Des-normalizamos las predicciones para que estén en la escala original de precios.\n",
    "predictions = scaler_pred.inverse_transform(predictions)\n",
    "y_test_inv = scaler_pred.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Visualizamos los resultados para comparar el precio real con el predicho.\n",
    "plt.figure(figsize=(14, 5))\n",
    "plot_index = data.index[train_size + SEQ_LENGTH:] # Obtenemos los índices de fecha correctos para el plot.\n",
    "plt.plot(plot_index, y_test_inv, color='blue', label='Precio Real')\n",
    "plt.plot(plot_index, predictions, color='red', label='Precio Predicho')\n",
    "plt.title('Predicción de Precios con Transformer')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Precio')\n",
    "plt.legend()\n",
    "# Guardamos el gráfico como una imagen.\n",
    "plt.savefig('prediction_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estrategia en backtrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la estrategia de trading para backtrader.\n",
    "class TransformerStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        # Cargamos el modelo y los scalers al iniciar la estrategia.\n",
    "        self.model = load_model('transformer_model.keras')\n",
    "        self.scaler = scaler\n",
    "        self.scaler_pred = scaler_pred\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "\n",
    "        # Creamos referencias a los datos y a los indicadores que usaremos.\n",
    "        self.data_close = self.datas[0].close\n",
    "        self.rsi = bt.indicators.RSI(self.datas[0], period=14)\n",
    "        self.macd = bt.indicators.MACD(self.datas[0], period_me1=12, period_me2=26, period_signal=9)\n",
    "        self.bbands = bt.indicators.BollingerBands(self.datas[0], period=20)\n",
    "        self.atr = bt.indicators.AverageTrueRange(self.datas[0], period=14)\n",
    "        self.stoch = bt.indicators.Stochastic(self.datas[0], period=14)\n",
    "\n",
    "    # El método `next` se ejecuta en cada barra (cada día en este caso).\n",
    "    def next(self):\n",
    "        # Esperamos a tener suficientes datos para hacer una predicción.\n",
    "        if len(self) < self.seq_length + 26: # 26 es un margen por el cálculo de indicadores como el MACD.\n",
    "            return\n",
    "\n",
    "        # Recopilamos los últimos `seq_length` valores de nuestros indicadores.\n",
    "        close_vals = self.data_close.get(size=self.seq_length)\n",
    "        rsi_vals = self.rsi.get(size=self.seq_length)\n",
    "        macd_vals = self.macd.macd.get(size=self.seq_length)\n",
    "        bbl_vals = self.bbands.lines.bot.get(size=self.seq_length)\n",
    "        bbm_vals = self.bbands.lines.mid.get(size=self.seq_length)\n",
    "        bbu_vals = self.bbands.lines.top.get(size=self.seq_length)\n",
    "        atr_vals = self.atr.get(size=self.seq_length)\n",
    "        stochk_vals = self.stoch.lines.percK.get(size=self.seq_length)\n",
    "        stochd_vals = self.stoch.lines.percD.get(size=self.seq_length)\n",
    "\n",
    "        # Creamos el array de entrada para el modelo.\n",
    "        input_array = np.array([\n",
    "            close_vals, rsi_vals, macd_vals, bbl_vals, bbm_vals, bbu_vals, \n",
    "            atr_vals, stochk_vals, stochd_vals\n",
    "        ]).T\n",
    "\n",
    "        # Normalizamos los datos de entrada y hacemos la predicción.\n",
    "        scaled_input = self.scaler.transform(input_array)\n",
    "        X_pred = np.array([scaled_input])\n",
    "        prediction_scaled = self.model.predict(X_pred)\n",
    "        prediction = self.scaler_pred.inverse_transform(prediction_scaled)[0][0]\n",
    "\n",
    "        # Lógica de trading: si la predicción es mayor que el precio actual, compramos. Si es menor, vendemos.\n",
    "        if prediction > self.data_close[0]:\n",
    "            if not self.position: # Si no tenemos una posición abierta.\n",
    "                self.buy()\n",
    "        elif prediction < self.data_close[0]:\n",
    "            if self.position: # Si tenemos una posición abierta.\n",
    "                self.sell()\n",
    "\n",
    "# --- Configuración y ejecución del backtest con Cerebro ---\n",
    "cerebro = bt.Cerebro() # Creamos una instancia de Cerebro, el motor de backtrader.\n",
    "data_feed = bt.feeds.PandasData(dataname=df) # Creamos un feed de datos a partir de nuestro DataFrame.\n",
    "cerebro.adddata(data_feed) # Añadimos los datos a Cerebro.\n",
    "cerebro.addstrategy(TransformerStrategy) # Añadimos nuestra estrategia.\n",
    "cerebro.broker.setcash(100000.0) # Configuramos el capital inicial.\n",
    "cerebro.broker.setcommission(commission=0.001) # Configuramos la comisión por operación.\n",
    "\n",
    "print(f'Capital Inicial: {cerebro.broker.getvalue()}')\n",
    "cerebro.run() # Ejecutamos el backtest.\n",
    "print(f'Capital Final: {cerebro.broker.getvalue()}')\n",
    "\n",
    "# Guardamos el gráfico del backtest. Se usa un truco para que no intente mostrarlo en pantalla.\n",
    "_original_show = plt.show\n",
    "plt.show = lambda: None\n",
    "fig = cerebro.plot(style='candlestick')[0][0]\n",
    "fig.savefig('backtest_plot.png')\n",
    "plt.show = _original_show # Restauramos la función original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}